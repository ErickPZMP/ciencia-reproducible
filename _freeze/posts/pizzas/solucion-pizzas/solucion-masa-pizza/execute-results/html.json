{
  "hash": "3240018e8a46cc3b543122fb7acf19e9",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Masa para Pizza\"\nauthor: [\"Miguel Equihua\"]\ndate: \"20/jun/2024\"\n\ndraft: true\ntoc: true\n\ncss: styles.css\n\nformat:\n  html:\n    code-fold: true\neditor_options: \n  chunk_output_type: console\n---\n\n\n\n\n\nEn esta libreta *RMarkdown* les comparto mis notas de lo que hice en relación con los datos de masa para pizza.\n\nEl Estudio de Marcelo es un experimento *completamente aleatorizado*, no hubo restricciones a la aleatorización como para producir **bloques** o división en parcelas (**parcela dividida**). Los tratamientos los ideó Marcelo como tratamientos factoriales, resultado de la combinación de cantidades variables de azúcar y leche, pero finalmente optó por tratarlas como una serie de recetas (sin decirnos que cantidad de leche o azúcar empleo, típico de los cocineros, guardar secretos), así que no nos queda otra que tratar al arreglo de tratamientos como una clasificación simple en *recetas* (ANOVA de una sola vía dirían otros). El modelo que describe esto es algo así:\n\n$$\ny_{ij} = \\mu + R_i + \\varepsilon_{j(i)}\n$$\n\nEn donde *i* tiene 4 niveles, uno por cada receta, *j* tiene 4 niveles, por el número de repeticiones de cada receta. Por lo tanto, los grados de libertad en el cuadro de análisis de la varianza deben ser 3 para las recetas y 12 para el error.\n\n## Exploración tabular de los datos\n\nUna vez leídos los datos del archivo plano *texto separado por comas*, con acrónimo csv), definí la columna *recetas* como *factor*, lo hice con la función `mutate` para interactuar con la tabla completa. Me asomé a los datos calculando los promedios por tratamiento. Seguí la metáfora de *tubos* con ayuda de la biblioteca `tidyverse` o `dplyr`.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# masa <- read_csv(\"masa-para-pizza.txt\", col_names = TRUE)\n\nurl_datos <- \"https://drive.google.com/file/d/1uVUOqwobv67E5xTsSSxjg9f9qypW-aIS/view\"\ndat_datos_id <- str_extract(url_datos, \"(?<=d/)(.*)(?=/view)\")\n\nurl_drive <- \"https://docs.google.com/uc?id=%s&export=download\" \nmasa <- read.csv(sprintf(url_drive, dat_datos_id)) \n\nmasa %>% \n  mutate(receta = factor(receta)) -> masa # también puedo guardar resultados así\n\nmasa %>% group_by(receta) %>% \n         summarise(media = median(tiempo, na.rm = TRUE), \n                   mediana = median(tiempo, na.rm = TRUE),\n                   var = var(tiempo))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 4\n  receta media mediana   var\n  <fct>  <dbl>   <dbl> <dbl>\n1 \" A\"    488.    488. 6340.\n2 \" B\"    192.    192. 4490.\n3 \" C\"    675     675  5491.\n4 \" D\"    175     175  2723.\n```\n\n\n:::\n:::\n\n\n\n## Exploración gráfica\n\nUse una gráfica simple con letras para las recetas para tener una idea de los datos. Usé la función `unclass`para obtener un índice numérico asociado con las recetas, así le doy fácilmente un color distinto a cada receta, aunque son los colores que sean, podría hacer algo semejante para escoger los colores de mi gusto o incluso hacer un vector de colores por nombre, pero para el caso exploratorio esto que hice es muy fácil y rápido.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(masa$tiempo, type = \"n\", ylab = \"tiempo\")\ntext(masa$tiempo, labels = masa$receta,\n     col = as.integer(unclass(masa$receta)))\n```\n\n::: {.cell-output-display}\n![](solucion-masa-pizza_files/figure-html/explora-1.png){width=672}\n:::\n:::\n\n\n\n## Prueba de hipótesis\n\nMe parece que hay buenas razones para pensar que puede detectarse un efecto importante de alguna de las recetas. No encuentro a simple vista mayores razones para pensar que haya heterogeneidad de varianzas o falta de normalidad, aunque los tratamientos de menor tiempo se ven algo más compactos que los más lentos (típico patrón que conduce a la _heterocedasticidad_, asociación de la varianza y la media). Pero empezaré con lo más simple.\n\n\n\n::: {.cell lst-title='lst-anls'}\n\n```{.r .cell-code  lst-cap=\"A ver\"}\nmasa_lm <- lm(tiempo ~ receta, data = masa)\nanova(masa_lm)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Variance Table\n\nResponse: tiempo\n          Df Sum Sq Mean Sq F value   Pr(>F)    \nreceta     3 638968  212989  44.739 8.64e-07 ***\nResiduals 12  57128    4761                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n\n```{.r .cell-code  lst-cap=\"A ver\"}\nsummary(masa_lm)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = tiempo ~ receta, data = masa)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-102.000  -39.375    3.875   49.000   88.750 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   486.25      34.50  14.095 7.90e-09 ***\nreceta B     -290.00      48.79  -5.944 6.78e-05 ***\nreceta C      169.75      48.79   3.479  0.00455 ** \nreceta D     -302.50      48.79  -6.200 4.59e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 69 on 12 degrees of freedom\nMultiple R-squared:  0.9179,\tAdjusted R-squared:  0.8974 \nF-statistic: 44.74 on 3 and 12 DF,  p-value: 8.64e-07\n```\n\n\n:::\n:::\n\n\n\nEl cuadro de ANOVA obtenido sugiere que es razonable rechazar la **H**<sub>0</sub> ómnibus, de manera que estamos justificados si optamos por considerar que todas o algunas recetas están produciendo tiempos *significativamente* distintos entre sí. El resumen sugiere, dada la reparametrización, que todas las recetas podrían ser distintas de la *A* y que la *D* está produciendo los tiempos más cortos de *leudado*, aunque en tal caso la receta *B* no está nada lejos. Claro, aquí ya me estoy dejando llevar por lo que ocurrió en este caso, así que estoy arriesgando la generalidad de mis conclusiones. De todos modos correré el riesgo. Una propuesta razonable para considerar esto sería la de proponer que las recetas *B* y *D* se comportan de manera equivalente y dejar *A* y *C* como dos variantes con mal desempeño. Pero, antes de pasar a eso veamos como se comporta el ajuste del modelo en relación con los supuestos estadísticos. Para eso, veamos gráficas de los residuos.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(masa_lm)\n```\n\n::: {.cell-output-display}\n![](solucion-masa-pizza_files/figure-html/graf-modelo-1-1.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](solucion-masa-pizza_files/figure-html/graf-modelo-1-2.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](solucion-masa-pizza_files/figure-html/graf-modelo-1-3.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](solucion-masa-pizza_files/figure-html/graf-modelo-1-4.png){width=672}\n:::\n:::\n\n\n\nMe parece que se ve un comportamiento bastante razonable en los residuos. Si nos ponemos estrictos a lo mejor el supuesto de normalidad en los residuos se ve un poco dudoso y quizás también un poco de heterogeneidad de varianzas. Pero nada muy marcado como para invalidar el ajuste del modelo.\n\nCon los resultados anteriores puedo avanzar con bastante confianza para atender la cuestión de *cuál será la receta con la que la masa sube más rápido*. La forma que elegí para hacer esto es seguir con un enfoque de modelación, reformular el modelo original y valorar si cambia en forma importante al redefinir el factor de recetas. Otras formas de hacerlo serían el recurrir a pruebas t pareadas, que es lo que Fisher llamó *pruebas protegidas* por que ya rechazamos la omnibus **H**<sub>0</sub>. Otra posibilidad es usar `TukeyHSD` de la biblioteca `stats` (se carga al abrir **R** sin preguntarnos), o podríamos recurrir a la [corrección de Boferroni](https://towardsdatascience.com/anova-vs-bonferroni-correction-c8573936a64e). Lo importante es no olvidar que cuando llegamos a este punto, estas comparaciones las hacemos en un ámbito en gran parte exploratorio. Por eso a mi me gusta mantenerme en el plan de que **el modelo es la historia** y buscar producir un modelo que incluya también esas comparaciones. Así lo hice. Por lo que vi en los coeficientes estimados las recetas parecen diferir casi todas en rendimiento, salvo la pareja *B-D* que son las que dan ttiempos más cortos, por lo tanto, la pregunta que para mi sigue es si un modelo en donde no distingo entre estas dos recetas, mantiene un buen ajuste a los datos observados.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmasa$receta_BD <- recode(masa$receta, B = \"BD\", D = \"BD\")\n\nmasa_lm_BD <- lm(tiempo ~ receta_BD, data = masa)\nanova(masa_lm_BD, masa_lm)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Variance Table\n\nModel 1: tiempo ~ receta_BD\nModel 2: tiempo ~ receta\n  Res.Df   RSS Df Sum of Sq F Pr(>F)\n1     12 57128                      \n2     12 57128  0         0         \n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(masa_lm_BD)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = tiempo ~ receta_BD, data = masa)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-102.000  -39.375    3.875   49.000   88.750 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   486.25      34.50  14.095 7.90e-09 ***\nreceta_BD B  -290.00      48.79  -5.944 6.78e-05 ***\nreceta_BD C   169.75      48.79   3.479  0.00455 ** \nreceta_BD D  -302.50      48.79  -6.200 4.59e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 69 on 12 degrees of freedom\nMultiple R-squared:  0.9179,\tAdjusted R-squared:  0.8974 \nF-statistic: 44.74 on 3 and 12 DF,  p-value: 8.64e-07\n```\n\n\n:::\n:::\n\n\n\nEste resultado me sugiere que hay una mínima pérdida de ajuste a los datos y que el nuevo modelo podría considerarse prácticamente equivalente a la versión más compleja que distingue cada receta. Así que la proposición de que es razonable considerar a las recetas *B* y *D* como equivalentes se puede defender. Al hacerlo no pierdo mucho de correspondencia entre los valores que produce el nuevo modelo y los datos. En realidad ya no me interesa averiguar que pasa con las otras recetas, pues ambas tienen un desempeño más lento que las que he indentificado, así que este modelo es el **mínimo adecuado para esta historia**. ¿Se habrá producido alguna distorsión en otros aspectos estadísticos del modelo?\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(masa_lm_BD)\n```\n\n::: {.cell-output-display}\n![](solucion-masa-pizza_files/figure-html/graf-combo-recetas-1.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](solucion-masa-pizza_files/figure-html/graf-combo-recetas-2.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](solucion-masa-pizza_files/figure-html/graf-combo-recetas-3.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](solucion-masa-pizza_files/figure-html/graf-combo-recetas-4.png){width=672}\n:::\n:::\n\n\n\nEl comportamiento de los residuos se ve muy semejante al comportamiento del modelo completo. Sigo sin ver mayores problemas en el ajuste. Es cierto que se ven detallitos que hacen tener ligeras dudas, quizás relacionados con heterocedasticidad. Así que hagamos algo al respecto, aunque no sea más que con **fines didácticos**.\n\n## Opciones avanzadas de análisis\n\n### Modelo ponderado\n\nLo que haremos es utilizar la opción `weight` de la función `lm`, esto nos permite hacer lo que se llama *modelos de regresión ponderados*. Hay muchas posibles razones para utilizar *esquemas de ponderación*, todos relacionados con la idea de que podemos proponer argumentos sobre qué datos deberían influir más sobre el ajuste del modelo. En este caso utilizaremos la idea que anoté al principio y que es relativamente común encontrarla en la práctica. Muchas veces pasa que cuando el tamaño de la respuesta aumenta también lo hace la variación con la que la observamos. Es decir a mayor media, mayor varianza. En el modelo ponderado lo podemos expresar pensando que deberíamos darle menos credibilidad (peso) a las observaciones asociadas con tratamientos que producen medias más grandes.\n\nA continuación les muestro como pondríamos estas ideas en práctica con `lm`. Lo que haré es construir una expresión que relacione el tamaño de los residuos con las medias de los tratamientos, lo que me permitirá estimar algo parecido a las varianzas asociadas con cada tratamiento en el modelo. A partir de ahí construyo la variable de ponderación que será un expresión relacionada con:\n\n$$\n  ponderador \\propto  \\frac{1}{\\sigma ^2}\n$$\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Modelo ponderado para enfrentarnos a la heterocedasticidad\n# Defino los ponderadores a usar\npond <- 1 / lm(abs(masa_lm$residuals) ~ masa_lm$fitted.values)$fitted.values^2\n\n# Ajusto un modelo ponderando dando mayor peso a los tratamientos con menor varianza\nmasa_lm_pond <- lm(tiempo ~ receta, data = masa, weights = pond)\nanova(masa_lm_pond)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Variance Table\n\nResponse: tiempo\n          Df  Sum Sq Mean Sq F value    Pr(>F)    \nreceta     3 223.626  74.542  42.822 1.097e-06 ***\nResiduals 12  20.889   1.741                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(masa_lm_pond)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = tiempo ~ receta, data = masa, weights = pond)\n\nWeighted Residuals:\n     Min       1Q   Median       3Q      Max \n-1.70827 -0.80847  0.09686  0.82064  1.79195 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   486.25      36.23  13.421 1.38e-08 ***\nreceta B     -290.00      47.57  -6.096 5.37e-05 ***\nreceta C      169.75      53.52   3.172  0.00804 ** \nreceta D     -302.50      47.42  -6.379 3.51e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.319 on 12 degrees of freedom\nMultiple R-squared:  0.9146,\tAdjusted R-squared:  0.8932 \nF-statistic: 42.82 on 3 and 12 DF,  p-value: 1.097e-06\n```\n\n\n:::\n\n```{.r .cell-code}\nplot((masa_lm_pond))\n```\n\n::: {.cell-output-display}\n![](solucion-masa-pizza_files/figure-html/modelo-pond-1.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](solucion-masa-pizza_files/figure-html/modelo-pond-2.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](solucion-masa-pizza_files/figure-html/modelo-pond-3.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](solucion-masa-pizza_files/figure-html/modelo-pond-4.png){width=672}\n:::\n:::\n\n\n\nComo cabría esperar, este modelo pierde un poco en ajuste, pero nada preocupante. Los resultados sostienen la misma historia que habíamos encontrado en el enfoque no ponderado y en todo caso se aprecia una pequeña mejora en cuanto a la preocupación de que hubiera heterocedasticidad en los datos y esto pudiera estar afectando los resultados.\n\nPara completar el análisis hago la valoración de la relevancia de separar las recetas *B* y *D* del resto. Considerando los mismos ponderadores que use con el modelo completo.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Ajusto un modelo ponderado con mayor peso los tratamientos con menor varianza\nmasa_lm_BD_pond <- lm(tiempo ~ receta_BD, data = masa, weights = pond)\nanova(masa_lm_pond, masa_lm_BD_pond)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Variance Table\n\nModel 1: tiempo ~ receta\nModel 2: tiempo ~ receta_BD\n  Res.Df    RSS Df Sum of Sq F Pr(>F)\n1     12 20.889                      \n2     12 20.889  0         0         \n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(masa_lm_BD_pond)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = tiempo ~ receta_BD, data = masa, weights = pond)\n\nWeighted Residuals:\n     Min       1Q   Median       3Q      Max \n-1.70827 -0.80847  0.09686  0.82064  1.79195 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   486.25      36.23  13.421 1.38e-08 ***\nreceta_BD B  -290.00      47.57  -6.096 5.37e-05 ***\nreceta_BD C   169.75      53.52   3.172  0.00804 ** \nreceta_BD D  -302.50      47.42  -6.379 3.51e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.319 on 12 degrees of freedom\nMultiple R-squared:  0.9146,\tAdjusted R-squared:  0.8932 \nF-statistic: 42.82 on 3 and 12 DF,  p-value: 1.097e-06\n```\n\n\n:::\n\n```{.r .cell-code}\nplot((masa_lm_BD_pond))\n```\n\n::: {.cell-output-display}\n![](solucion-masa-pizza_files/figure-html/modPond-combo-1.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](solucion-masa-pizza_files/figure-html/modPond-combo-2.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](solucion-masa-pizza_files/figure-html/modPond-combo-3.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](solucion-masa-pizza_files/figure-html/modPond-combo-4.png){width=672}\n:::\n:::\n\n\n\nLos resultados se sostienen. Quizás ahora la falta de normalidad podría ser una inquietud, pero dada la congruencia entre los resultados de los varios modelos, sospecho que no está afectando fundamentalmente la naturaleza del patrón que estamos detectando. Marcelo debería tener mucha confianza al afirmar que las recetas *B* y *D* tiene un mejor desempeño que las otras dos y que entre estas dos no hay una diferencia detectable.\n\n### Offset: Modelo \"redondeado\"\n\nUn último asunto ¿cómo puedo poner a prueba hipótesis de interés que no sean la *H*<sub>0</sub>=0?. Una manera es recurrir a la opción `offset` en **R**. A continuación muestro una forma de hacerlo. Lo que haré es tomar los coeficientes estimados y redondearlos, para ver que tanto de la capacidad predictiva del ajuste se pierde en la *versión simplificada* por el acto de redondear.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Tomo los coeficientes estimados del modelo y elimino todos los decimales\ncoef_BD_pond <- round(coef(masa_lm_BD_pond), 0)\ncoef_BD_pond\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n(Intercept) receta_BD B receta_BD C receta_BD D \n        486        -290         170        -302 \n```\n\n\n:::\n:::\n\n\n\nComo vimos en clase, puedo obtener la matriz de variables explicativas (*dummy* o no) incluidas en el modelo con la función `model.matrix`. Si multiplico las columnas de esta matriz por el coeficiente que le corresponde (multiplicación normal, no matricial), tengo una nueva matriz que contiene en cada renglón, el valor que predice el modelo ajustado para la observación correspondiente.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# La matriz del modelo es esta\nbd_pond_mat <- model.matrix(masa_lm_BD_pond)\n\n\n# Ahora tenemos que armar la matriz con el modelo para cada renglón\nmode_off <-  data.frame(intercept = coef_BD_pond[1] * bd_pond_mat[, 1],\n                        receta_BD = coef_BD_pond[2] * bd_pond_mat[, 2],\n                        receta_C  = coef_BD_pond[3] * bd_pond_mat[, 3],\n                        receta_D  = coef_BD_pond[4] * bd_pond_mat[, 4])\nmode_off\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   intercept receta_BD receta_C receta_D\n1        486         0        0        0\n2        486         0        0        0\n3        486      -290        0        0\n4        486      -290        0        0\n5        486         0      170        0\n6        486         0      170        0\n7        486         0        0     -302\n8        486         0        0     -302\n9        486         0        0        0\n10       486         0        0        0\n11       486      -290        0        0\n12       486      -290        0        0\n13       486         0      170        0\n14       486         0      170        0\n15       486         0        0     -302\n16       486         0        0     -302\n```\n\n\n:::\n\n```{.r .cell-code}\n# Otra forma de hacer esto mismo es esta\nmode_off_2 <- t(coef_BD_pond * t(model.matrix(masa_lm_BD_pond)))\n\nmode_off_2 == mode_off\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   intercept receta_BD receta_C receta_D\n1       TRUE      TRUE     TRUE     TRUE\n2       TRUE      TRUE     TRUE     TRUE\n3       TRUE      TRUE     TRUE     TRUE\n4       TRUE      TRUE     TRUE     TRUE\n5       TRUE      TRUE     TRUE     TRUE\n6       TRUE      TRUE     TRUE     TRUE\n7       TRUE      TRUE     TRUE     TRUE\n8       TRUE      TRUE     TRUE     TRUE\n9       TRUE      TRUE     TRUE     TRUE\n10      TRUE      TRUE     TRUE     TRUE\n11      TRUE      TRUE     TRUE     TRUE\n12      TRUE      TRUE     TRUE     TRUE\n13      TRUE      TRUE     TRUE     TRUE\n14      TRUE      TRUE     TRUE     TRUE\n15      TRUE      TRUE     TRUE     TRUE\n16      TRUE      TRUE     TRUE     TRUE\n```\n\n\n:::\n:::\n\n\n\nAhora pongamos a prueba que tan bien funciona esta versión *redondeada* del modelo que hemos ajustado.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# valora-modelos\n\nmasa_lm_BD_pond_off <- lm(tiempo ~ receta_BD, data = masa, \n                        weights = pond, \n                        offset = (mode_off[,1] + mode_off[,2] + \n                                  mode_off[, 3] + mode_off[, 4]))\n\nsummary(masa_lm_BD_pond_off)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = tiempo ~ receta_BD, data = masa, weights = pond, \n    offset = (mode_off[, 1] + mode_off[, 2] + mode_off[, 3] + \n        mode_off[, 4]))\n\nWeighted Residuals:\n     Min       1Q   Median       3Q      Max \n-1.70827 -0.80847  0.09686  0.82064  1.79195 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)\n(Intercept)  2.500e-01  3.623e+01   0.007    0.995\nreceta_BD B  1.334e-14  4.757e+01   0.000    1.000\nreceta_BD C -2.500e-01  5.352e+01  -0.005    0.996\nreceta_BD D -5.000e-01  4.742e+01  -0.011    0.992\n\nResidual standard error: 1.319 on 12 degrees of freedom\nMultiple R-squared:  1.419e-05,\tAdjusted R-squared:  -0.25 \nF-statistic: 5.675e-05 on 3 and 12 DF,  p-value: 1\n```\n\n\n:::\n\n```{.r .cell-code}\nanova(masa_lm_BD_pond_off)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Variance Table\n\nResponse: tiempo\n          Df  Sum Sq Mean Sq F value Pr(>F)\nreceta_BD  3  0.0003  0.0001   1e-04      1\nResiduals 12 20.8887  1.7407               \n```\n\n\n:::\n:::\n\n\n\nComo puedes ver funciona muy bien, es prácticamente indistinguible del modelo ajustado con todas las cifras significativas que resultaron del cálculo que hizo la computadora. Hay uun correspondencia término a término entre el *offset* y los coeficientes estimados y ahí también puede verse que los coeficientes corresponden muy bien y dado el *offcet*, no habría razón para estimarlos con algún ajuste. Las sumas de cuadrados residuales son prácticamente iguales en las dos versiones del modelo, difiere en menos de $1 \\times 10^{-14}$ en el estimador de varianza del error. No habría razón para no entregarle esa ecuación con coeficientes redondeados a Marcelo para que hiciera cálculos futuros al preparar pizzas.\n\n## Tarea\n\nDe hecho, ¿por qué no repetimos este experimento en casa? Se los propongo como tarea y si les parece bien, habría que reunir los datos, organizarlos para tenerlos en la nube de Google Drive y repetir individualmente el proceso analítico que vimos aquí, por lo menos los elementos básicos de la _prueba de hipótesis_.A partir de la experiencia, podremos empezar por discutir el diseño experimental, convenir en lo que harán y podríamos finalmente discutir ideas sobre *reroducibilidad*, considerando los hallazgos de cada quién y de todos en conjunto.\n\n::: {.callout-tip collapse=\"true\"}\n## Referencia\n\n+ Harina: 150 g\n+ Agua: 50 ml \n+ Leche: 25 ml\n+ Azucar: 1/3 cdt\n+ Levadura seca: 1/3 sobre (sobre de 11g)\n\n:::\n",
    "supporting": [
      "solucion-masa-pizza_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}